# For env setup see for example at CERN:
#   $SavedFMa/cmssw/cmssw_2_1_X/grid/crab/scripts/setcrab.sh

[CRAB]

jobtype = cmssw
scheduler = glitecoll
### NOTE: just setting the name of the server (pi, lnl etc etc ) 
###       crab will submit the jobs to the server...   
#server_name = bari

[CMSSW]

### The data you want to access (to be found on DBS) 
#datasetpath=/QCD_EMenriched_Pt30to80/Summer08_IDEAL_V6_RECO_v1/GEN-SIM-RECO
#datasetpath=/TauolaTTbar/Summer08_IDEAL_V6_v1/GEN-SIM-RECO
datasetpath=/MinBias/Summer08_STARTUP_V5_STARTUP_V5_v1/GEN-SIM-RAW

### The ParameterSet you want to use
#pset=MitFiller_emEnrichedQCDPt30-80.py
#pset=HLTrigger/Configuration/test/digi_digi2raw/crabL1prescaledRelVal_Digi_Digi2Raw.cfg
#pset=/export/04a/frankma/cmssw/l1skimCMSSW_2_1_7/src/hlt/l1skim/test/prod/prod_digi_l1_digi2raw/STARTUP_V5/STARTUPV5_DIGI_L1_skim_DIGI2RAW_cfg.py
pset=/home/frankma/UserCode/SavedFMa/cmssw/cmssw_2_1_X/hlt/l1skim/test/prod/prod_digi_l1_digi2raw/STARTUP_V5/testcrab/STARTUPV5_DIGI_L1_skim_DIGI2RAW_cfg.py

### Splitting parameters
#for testing
#total_number_of_events=10
#events_per_job = 10
#number_of_jobs = 10

#--For production--
#total_number_of_events=100000
#total_number_of_events=10000
#events_per_job = 10000
#events_per_job = 250
#number_of_jobs = 10
#--For testing--
total_number_of_events=1000
events_per_job = 100

### The output files (comma separated list)
#output_file = ttbar-id6_000.root
output_file = Summer08_MinBias_STARTUPV5_L1skimmed_Raw.root

[USER]

### OUTPUT files Management
##  output back into UI 
#return_data = 0
return_data = 1

### OUTPUT files INTO A SE
#copy_data = 1
copy_data = 0
#storage_element = srm-cms.cern.ch
#storage_path = /srm/managerv2?SFN=/castor/cern.ch/user/s/sixie/OAKSamples/ttbar-id6
#storage_path = /srm/managerv2?SFN=/castor/cern.ch/user/s/sixie/OAKSamples/test
#storage_path = /srm/managerv2?SFN=/castor/cern.ch/user/f/frankma/data/cmssw/217/l1skim/prod/prod_digi_l1_digi2raw/STARTUP_V5

#if server 
#thresholdLevel = 100
#eMail = frankma@mit.edu 

[EDG]

## RB/WMS management:
rb = CERN
proxy_server = myproxy.cern.ch

##  Black and White Lists management:
## By Storage
#se_black_list = 
#se_white_list = 

## By ComputingElement 
#ce_black_list = 
#ce_white_list = 

[CONDORG]

# Set this to condor to override the batchsystem defined in gridcat.
#batchsystem = condor

# Specify addition condor_g requirments
# use this requirment to run on a cms dedicated hardare
# globus_rsl = (condor_submit=(requirements 'ClusterName == \"CMS\" && (Arch == \"INTEL\" || Arch == \"X86_64\")'))
# use this requirement to run on the new hardware
#globus_rsl = (condor_submit=(requirements 'regexp(\"cms-*\",Machine)'))

